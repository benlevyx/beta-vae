\section{Introduction}

A $\beta$-variational autoencoder ($\beta$-VAE) is a family of unsupervised models whose goal is to infer a ``disentangled," low-dimensional representation of some high-dimensional data, often images \cite{weng2018VAE}. In general, auto-encoders seek to reconstruct some input $\vx\in\R^d$ while simultaneously learning a latent representation, $\vz\in\R^k$, which is typically chosen to be lower-dimensional than $\vx$. This is accomplished by training two models: an encoder parameterized by $\phi$, denoted $g_\phi(\vx)$, and a decoder parameterized by $\theta$, denoted $f_\theta(\vz)$. The algorithm is, roughly:
\begin{enumerate}
    \item Given example $\vx$, compute $\vz = g_\phi(\vx)$
    \item Compute reconstruction $\hat{x} = f_\theta(\vz)$
\end{enumerate}
A limitation of this deterministic autoencoder is that the latent space in which $\vz$ resides is typically quite sparse and/or irregular. This can make it difficult to use the latent representations for inference or other purposes. Variational auto-encoders (VAEs) improve upon this by replacing the decoder $f_\theta$ with a stochastic sampling function. Consequently, $g_\phi$ now outputs a mean $\vmu$ and a covariance $\Sigma$, which parameterize a Gaussian distribution \cite{kingma2013auto}. The algorithm then becomes:
\begin{enumerate}
    \item Given example $\vx$, compute ($\vmu, \Sigma) = g_\phi(\vx)$
    \item Sample latent variable $\vz \sim \N(\vmu, \Sigma)$
    \item Compute reconstruction $\hat{x} = f_\theta(\vz)$
\end{enumerate}

To make this model tractable, we typically use isotropic Gaussians, meaning the covariance matrix $\Sigma$ is diagonal. By replacing the deterministic algorithm with a stochastic one, the model is forced to learn latent representations that are more robust to Gaussian noise, since if small perturbations led to dramatically different outputs, the model would perform poorly at reconstructing the output. The loss function for the VAE can be expressed as a sum of two terms: (1) reconstruction error and (2) regularization (defined more rigorously later on in the methods section). The reconstruction term pushes the model to faithfully reconstruct the original data, while the regularization term encourages the model to learn a generalizable and efficient latent representation.

While the VAE model solves the problem of irregular latent spaces, there are no guarantees that the latent representations are {\it meaningful}. This gives rise to the idea of {\it disentanglement}, which is roughly the notion that the different components of the latent variable $\vz$ should correspond to distinct {\it generative factors} (i.e. the parameters of the generative process) \cite{bengio2012representation}. For instance, if we are modelling an image dataset consisting of human faces, we might want one dimension to correspond to skin tone, another to correspond to eye shape, a further one to correspond to amount of hair, and so on. Introduced by Burgess et al. in 2018, the $\beta$-VAE is a model designed with this goal in mind \cite{higgins2016beta}. An additional hyperparameter, $\beta \in \R$ is added as a coefficient for the regularization term from the VAE loss. When $\beta=1$, the loss function is identical to the original VAE loss function. When $\beta > 1$, the model is forced to learn a less expressive, and therefore more information-dense, latent encoding for the data. Furthermore, the representations learned by $\beta$-VAE tend to be more disentangled, meaning that it is more possible to recover the original factors that may have generated the data.

In the landscape of dimensionality reduction techniques, $\beta$-VAE (and all types of VAE) are non-linear. The data domain (images) is such that the data are extremely high dimensional but the dimensions have highly complex relationships with one another, both geometrically and semantically. It is for this reason that simpler, more linear dimensionality reduction techniques, like PCA, or manifold-based techniques, like ISOMAP, are less likely to be able to perform well on image data, while VAE's can. However, this additional flexibility comes at the cost of reduced interpretability, since we no longer have any guarantees about the geometric relationship between the data space and latent space. This is where $\beta$-VAEs come in: by reducing the flexibility of the latent space, we can hopefully gain more interpretability in the low-dimensional representations.